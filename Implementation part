from google.colab import drive
drive.mount('/content/drive')
#Import libraries
import numpy as np
import pandas as pd
from datetime import datetime

#dateparse = lambda x: datetime.strptime(x, '%d-%m-%Y %H:%M')
dateparse = lambda x: datetime.strptime(x, '%d-%m-%Y')

df = pd.read_csv('/content/drive/MyDrive/Copy of data1.csv', parse_dates=[0], date_parser=dateparse, index_col=0)

data_monthly = df.resample('M').mean()
data_monthly = pd.DataFrame(data_monthly)
data_monthly.to_csv('/content/drive/MyDrive/Copy of monthly.csv')
!pip install netCDF4
import netCDF4
import numpy
import xarray

# Change combine to 'nested' and keep concat_dim="time"
ds = xarray.open_mfdataset('/content/drive/MyDrive/Copy of merged.nc4', combine='nested', concat_dim="time")
ds.to_netcdf('1980-1990.nc4')

import xarray as xr
import pandas as pd

data = xr.open_dataset('/content/drive/MyDrive/Copy of kanpur.nc4')
df = data.to_dataframe().reset_index()
df.to_csv('kanpur.csv')

#Import libraries
import numpy as np
import pandas as pd
from datetime import datetime

dateparse = lambda x: datetime.strptime(x, '%d-%m-%Y %H:%M')
#dateparse = lambda x: datetime.strptime(x, '%d-%m-%Y')

df = pd.read_csv('/content/drive/MyDrive/Copy of kanpur.csv', parse_dates=[0],index_col=0)

data_hourly = df.resample('D').mean()
data_hourly = pd.DataFrame(data_hourly)
data_hourly.to_csv('daily.csv')

data_monthly = df.resample('M').mean()
data_monthly = pd.DataFrame(data_monthly)
data_monthly.to_csv('monthly.csv')
# Inspect the data
daily_data = pd.read_csv('daily.csv')
print(daily_data.head())

monthly_data = pd.read_csv('monthly.csv')
print(monthly_data.head())
#Import Libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_validate
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

data = pd.read_csv('/content/drive/MyDrive/Copy of scatter_plot.csv')

X = data[['Aeronet']].va lues
y = data[['Merra']].values
LR = LinearRegression().fit(X, y)
y_pred = LR.predict(X)

slope = str(np.round(LR.coef_, 2))
intercept = str(np.round(LR.intercept_, 2))
slope = slope.strip("[-2,2]")
intercept = intercept.strip("[-1,1]")

R2 = r2_score(y, y_pred)
RMSE = mean_squared_error(y, y_pred, squared=False)
MAE = mean_absolute_error(y, y_pred)

R2 = str(np.round(R2, 2))
RMSE = str(np.round(RMSE, 2))
MAE = str(np.round(MAE, 2))

plt.scatter(X, y, color='red', marker='.')
plt.plot(X, y_pred, color='black', linewidth=3)
plt.xlabel('AERONET')
plt.ylabel('MERRA2')
plt.text(0.5,0.99, "$AOD_{MERRA2}$ = "+ str(slope) + " * $AOD_{AERONET}$ + " + str(intercept), transform=plt.gca().transAxes, va = "top", ha="left")
plt.text(0.5,0.94, "R\N{SUPERSCRIPT TWO} = "+ str(R2), transform=plt.gca().transAxes, va = "top", ha="left")
plt.text(0.5,0.89, "RMSE = "+ str(RMSE), transform=plt.gca().transAxes, va = "top", ha="left")
plt.text(0.5,0.84, "MAE = "+ str(MAE), transform=plt.gca().transAxes, va = "top", ha="left")
#plt.savefig("Plots\LCS_DT_PM2.5_"+ datetime.now().strftime("%d-%m-%Y") + ".png", format='png', dpi=1200)
plt.show()

"""
print(LR.coef_)
print(LR.intercept_)
print('LR R2:', r2_score(y, y_pred))
print('LR MSE', mean_squared_error(y, y_pred))
print('LR MAE', mean_absolute_error(y, y_pred))

plt.scatter(X, y)
plt.plot(X, y_pred, color='red')
plt.xlabel('Aeronet')
plt.ylabel('Merra')
plt.show()
"""#Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('/content/drive/MyDrive/Copy of line_plot.csv')

df.plot(x="Month", y=["2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019"], kind="line")
plt.legend()
plt.show()


df.plot(x="Month", y=["2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019"], kind="bar")
plt.legend()
plt.show()
#Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('/content/drive/MyDrive/Copy of box_plot.csv')

df.plot(y=["2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019"], kind="box")
plt.legend()
plt.show()

print(df.columns)
for year in df.columns:
    # Perform operations, e.g., printing or calculations
    print(f"Data for {year}:")
    print(df[year].head())
print(text_combined)
text_combined = " ".join(df[col] for col in df.columns if df[col].dtype == 'object')
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load and check the dataframe (replace NaNs with zeros for numeric data)
df = df.fillna(0)

# Ensure we only use numeric columns for visualizations
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns

# 1. Correlation Heatmap for numerical columns
if len(numeric_columns) > 1:
    corr_matrix = df[numeric_columns].corr()
    plt.figure(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True)
    plt.title("Correlation Matrix Heatmap")
    plt.show()
else:
    print("Not enough numerical columns for a correlation heatmap.")

# 2. Histograms for each numerical column
for col in numeric_columns:
    plt.figure(figsize=(8, 5))
    df[col].hist(bins=20, color='skyblue', edgecolor='black')
    plt.title(f"Distribution of Values in {col}")
    plt.xlabel("Values")
    plt.ylabel("Frequency")
    plt.show()

# 3. Box Plot to compare numerical values across different columns
if len(numeric_columns) > 1:
    plt.figure(figsize=(12, 6))
    sns.boxplot(data=df[numeric_columns])
    plt.title("Box Plot of Values Across Numerical Columns")
    plt.xlabel("Columns")
    plt.ylabel("Values")
    plt.show()
else:
    print("Not enough numerical columns for a box plot.")

# 4. Line Plot to show trends over time (if data is yearly or sequential)
# Assuming columns represent years, sort columns to ensure they are in ascending order if they are not already
sorted_numeric_columns = sorted(numeric_columns, key=lambda x: int(x) if x.isdigit() else x)
df_sorted = df[sorted_numeric_columns]

# Line plot for trends over years
plt.figure(figsize=(10, 6))
for col in df_sorted.columns:
    plt.plot(df_sorted.index, df_sorted[col], marker='o', label=col)
plt.title("Trend of Values Over Time")
plt.xlabel("Index")
plt.ylabel("Values")
plt.legend(title="Year Columns", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import zscore
from statsmodels.tsa.seasonal import seasonal_decompose
import plotly.express as px
import plotly.subplots as sp
from plotly.graph_objs import Scatter, Box, Histogram
from statsmodels.tsa.arima.model import ARIMA

# Sample data creation to simulate the structure based on provided index '2010' - '2019'
np.random.seed(42)
years = [str(year) for year in range(2010, 2020)]
data = np.random.rand(100, len(years))  # Simulate 100 rows of random data for each year
df = pd.DataFrame(data, columns=years)
print(df.head())

# Z-score anomaly detection
df_z = df.apply(zscore)
anomalies = (df_z.abs() > 3)  # Mark values with Z-score > 3 as anomalies
print(anomalies.head())
# Pairwise Correlation Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(df[years].corr(), annot=True, cmap="coolwarm", vmin=-1, vmax=1)
plt.title("Pairwise Correlation Heatmap")
plt.show()
# Interactive line plot for time-series trends
fig = px.line(df, x=df.index, y=years, title="Interactive Line Plot over Years")
fig.update_layout(xaxis_title="Index", yaxis_title="Values")
fig.show()
fig = sp.make_subplots(rows=3, cols=len(years)//3, subplot_titles=years)
# Populate subplots with histograms, box plots, and line plots
for i, col in enumerate(years):
    fig.add_trace(Histogram(x=df[col], name=f"{col} Distribution"), row=1, col=i % 3 + 1)
    fig.add_trace(Box(y=df[col], name=f"{col} Spread"), row=2, col=i % 3 + 1)
    fig.add_trace(Scatter(y=df[col], mode='lines', name=f"{col} Trend"), row=3, col=i % 3 + 1)

fig.update_layout(height=800, title="Combined Visualizations for Each Year")
fig.show()
# Time-Series Decomposition for one sample column
decomposed = seasonal_decompose(df['2010'], model='additive', period=12)
decomposition_fig = decomposed.plot()
decomposition_fig.suptitle("Seasonal Decomposition of 2010 Data")
plt.show()
# Import libraries
import numpy as np
import pandas as pd
from datetime import datetime
from statsmodels.tsa.seasonal import seasonal_decompose
import matplotlib.pyplot as plt

# Date parser for reading dates from the CSV
dateparse = lambda x: datetime.strptime(x, '%d-%m-%Y')

# Read the CSV file, parsing the first column as dates
df = pd.read_csv('/content/drive/MyDrive/Copy of data1.csv', parse_dates=[0], date_parser=dateparse, index_col=0)

# Resample the data to monthly frequency, taking the mean
data_monthly = df.resample('M').mean()

# Check for missing values in the monthly data
print("Missing values before filling:")
print(data_monthly.isnull().sum())

# Fill missing values - using forward fill as an example
data_monthly.fillna(method='ffill', inplace=True)

# Alternatively, to drop rows with missing values, uncomment the next line
# data_monthly.dropna(inplace=True)

# Check again for missing values after handling
print("Missing values after filling:")
print(data_monthly.isnull().sum())

# Time-Series Decomposition for the first column of the monthly data
decomposed = seasonal_decompose(data_monthly[data_monthly.columns[0]], model='additive', period=12)

# Plotting the decomposition
decomposition_fig = decomposed.plot()
decomposition_fig.suptitle("Seasonal Decomposition of First Column Data")
plt.show()
# Import libraries
import numpy as np
import pandas as pd
from datetime import datetime
from statsmodels.tsa.seasonal import seasonal_decompose
import matplotlib.pyplot as plt

# Date parser for reading dates from the CSV
dateparse = lambda x: datetime.strptime(x, '%d-%m-%Y')

# Read the CSV file, parsing the first column as dates
df = pd.read_csv('/content/drive/MyDrive/Copy of data1.csv', parse_dates=[0], date_parser=dateparse, index_col=0)

# Resample the data to monthly frequency, taking the mean
data_monthly = df.resample('M').mean()

# Check for missing values in the monthly data
print("Missing values before filling:")
print(data_monthly.isnull().sum())

# Fill missing values - using forward fill as an example
data_monthly.fillna(method='ffill', inplace=True)

# Alternatively, to drop rows with missing values, uncomment the next line
# data_monthly.dropna(inplace=True)

# Check again for missing values after handling
print("Missing values after filling:")
print(data_monthly.isnull().sum())

# Rolling Mean Calculation
window_size = 3  # You can adjust the window size as needed
data_monthly['Rolling Mean'] = data_monthly[data_monthly.columns[0]].rolling(window=window_size).mean()

# Time-Series Decomposition for the first column of the monthly data
decomposed = seasonal_decompose(data_monthly[data_monthly.columns[0]], model='additive', period=12)

# Plotting the original time series and rolling mean
plt.figure(figsize=(14, 10))

# Subplot for Original Time Series and Rolling Mean
plt.subplot(4, 1, 1)
plt.plot(data_monthly[data_monthly.columns[0]], label='Monthly Data', color='blue')
plt.plot(data_monthly['Rolling Mean'], label='Rolling Mean', color='orange')
plt.title('Original Time Series and Rolling Mean')
plt.xlabel('Date')
plt.ylabel('Values')
plt.legend()

# Plotting Seasonal Decomposition Components
plt.subplot(4, 1, 2)
plt.plot(decomposed.trend, label='Trend', color='green')
plt.title('Trend Component')
plt.xlabel('Date')
plt.ylabel('Values')
plt.legend()

plt.subplot(4, 1, 3)
plt.plot(decomposed.seasonal, label='Seasonal', color='purple')
plt.title('Seasonal Component')
plt.xlabel('Date')
plt.ylabel('Values')
plt.legend()

plt.subplot(4, 1, 4)
plt.plot(decomposed.resid, label='Residual', color='red')
plt.title('Residual Component')
plt.xlabel('Date')
plt.ylabel('Values')
plt.legend()

# Adjust layout
plt.tight_layout()
plt.show()
